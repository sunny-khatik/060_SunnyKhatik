{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-linear-regression-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "v0BtAX1--7l_"
      },
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecc6e79cdfb6a8ca882895ccc895b61b960b0a04",
        "id": "i1HSrBDb-7t9"
      },
      "source": [
        "## Linear Regression Model using PyTorch built-ins\n",
        "\n",
        "Let's re-implement the same model using some built-in functions and classes from PyTorch.\n",
        "\n",
        "And now using two different targets: Apples and Oranges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ce66cf0d09a3f38bf2f00ea40418c56d98f1f814",
        "id": "iXiEK54j-7t-"
      },
      "source": [
        "# Imports\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "74bb18bd01ac809079eeb8d05695206e8ba02069",
        "id": "wCsxgTWO-7uM"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d94b355f55250e9c7dcff668920f02d7c5c04925",
        "id": "nJRlm4-N-7uY"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a0665466eb5401f40a816b323a34450b2c052c41",
        "id": "O6JT5Ng6-7uj"
      },
      "source": [
        "### Dataset and DataLoader\n",
        "\n",
        "We'll create a `TensorDataset`, which allows access to rows from `inputs` and `targets` as tuples. We'll also create a DataLoader, to split the data into batches while training. It also provides other utilities like shuffling and sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "206f5fd0473386476b23477bf38d2c327b6376c9",
        "id": "iGYdbuWc-7ul"
      },
      "source": [
        "# Import tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c47a4f2f86fda3918094e01cf7ab0698bbb5acc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY_cq6Bf-7ux",
        "outputId": "9b7899ea-b802-4f72-d031-8087601d8f64"
      },
      "source": [
        "# Define dataset\n",
        "#The TensorDataset allows us to access a small section of the training data using the array indexing notation ([0:3] in the above code). \n",
        "#It returns a tuple (or pair), in which the first element contains the input variables for the selected rows, and the second contains the targets.\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0a2f69126319d738b82ae67d5d404ecd6161bfac",
        "id": "I-_dMpco-7u-"
      },
      "source": [
        "# Define data loader\n",
        "#DataLoader, which can split the data into batches of a predefined size while training. \n",
        "#It also provides other utilities like shuffling and random sampling of the data\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size = 5\n",
        "Train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "276a262e1b9e3a048bcd32989013f9c501c59037",
        "id": "Dq8gUbVx-7vK"
      },
      "source": [
        "### nn.Linear\n",
        "Instead of initializing the weights & biases manually, we can define the model using `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "59da3506559a0640d80d18f77b02726a1757be2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKa873ZD-7vN",
        "outputId": "6f13b804-f358-4e1c-fad1-140525e73d49"
      },
      "source": [
        "# Define model\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3248, -0.0474, -0.3284],\n",
            "        [ 0.5638, -0.4717, -0.4410]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2963,  0.0788], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b3a4a8c499a4680f2533329712de034671dd1cdd",
        "id": "rku14lz3-7vX"
      },
      "source": [
        "### Optimizer\n",
        "Instead of manually manipulating the weights & biases using gradients, we can use the optimizer `optim.SGD`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1848398bd1ced8c25a7bb55612cf32a774500280",
        "id": "Yd4H-T8g-7va"
      },
      "source": [
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "28cbe62be55010bd11b31d819cff38da5a772b18",
        "id": "V2ktEA-C-7vl"
      },
      "source": [
        "### Loss Function\n",
        "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "69d7f4e8e27ccd077f711da27f8bede8aa711893",
        "id": "TF2xmzgO-7vo"
      },
      "source": [
        "# Import nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a02ff888ed4be720fd9ca376022d8fdcf2559683",
        "id": "hSgxvr8N-7vz"
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a540adf76725ea9968025f6c029fdd251bdada6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vyVL5io-7wA",
        "outputId": "6b47e93e-cc4b-4a42-fee3-c81b2a161dac"
      },
      "source": [
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16121.4258, grad_fn=<MseLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e833614a69ff18c554a3d89f643ae2f11e0260f6",
        "id": "9jbPdkiO-7wM"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We are ready to train the model now. We can define a utility function `fit` which trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "128bc7260221f5338edf8b503c75f0c7d1cce7e8",
        "id": "zDnWui7g-7wP"
      },
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in Train_dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ae8ca4686cf6a68f6c9ca93bf3d227abe96c2201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd8tiT_q-7wa",
        "outputId": "cfcb839a-5fbf-4008-a496-7d0a7699799a"
      },
      "source": [
        "# Train the model for 100 epochs\n",
        "fit(100, model, loss_fn, opt)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 261.2181\n",
            "Epoch [20/100], Loss: 220.5679\n",
            "Epoch [30/100], Loss: 351.7696\n",
            "Epoch [40/100], Loss: 265.6008\n",
            "Epoch [50/100], Loss: 258.4625\n",
            "Epoch [60/100], Loss: 141.1492\n",
            "Epoch [70/100], Loss: 108.1234\n",
            "Epoch [80/100], Loss: 85.0864\n",
            "Epoch [90/100], Loss: 68.0635\n",
            "Epoch [100/100], Loss: 9.0222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "32588a47d0478772a1f08fa55874a322630bd0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Bf-Emn-7wj",
        "outputId": "ba189087-3151-4834-8999-6dd021dc99db"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.2473,  72.6485],\n",
              "        [ 79.5877,  97.0089],\n",
              "        [122.4195, 136.9993],\n",
              "        [ 27.7066,  50.4248],\n",
              "        [ 93.4755, 104.9967],\n",
              "        [ 58.2473,  72.6485],\n",
              "        [ 79.5877,  97.0089],\n",
              "        [122.4195, 136.9993],\n",
              "        [ 27.7066,  50.4248],\n",
              "        [ 93.4755, 104.9967],\n",
              "        [ 58.2473,  72.6485],\n",
              "        [ 79.5877,  97.0089],\n",
              "        [122.4195, 136.9993],\n",
              "        [ 27.7066,  50.4248],\n",
              "        [ 93.4755, 104.9967]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "12d757c0f37c2e3af65cf9d4b59878cc10c65acf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gDGmiHl-7wr",
        "outputId": "02a7103d-3225-4943-8d75-0207eb7316a7"
      },
      "source": [
        "# Compare with targets\n",
        "targets"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2448d9832722f4f2813f8bd80b91daefd901dc2e",
        "id": "b9nvUidI-7xD"
      },
      "source": [
        "Now we can define the model, optimizer and loss function exactly as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e94de6868c76803a998c1c1934ed229c826f3b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3esiKz3-7xT",
        "outputId": "d9880ae2-dfe5-4321-a569-8f945929ad93"
      },
      "source": [
        "fit(200, model, loss_fn, opt)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Loss: 47.1278\n",
            "Epoch [20/200], Loss: 31.7852\n",
            "Epoch [30/200], Loss: 30.3764\n",
            "Epoch [40/200], Loss: 33.3291\n",
            "Epoch [50/200], Loss: 25.2930\n",
            "Epoch [60/200], Loss: 19.5378\n",
            "Epoch [70/200], Loss: 22.2039\n",
            "Epoch [80/200], Loss: 15.1245\n",
            "Epoch [90/200], Loss: 34.3482\n",
            "Epoch [100/200], Loss: 17.8636\n",
            "Epoch [110/200], Loss: 18.6000\n",
            "Epoch [120/200], Loss: 10.8680\n",
            "Epoch [130/200], Loss: 22.4854\n",
            "Epoch [140/200], Loss: 17.1396\n",
            "Epoch [150/200], Loss: 9.1551\n",
            "Epoch [160/200], Loss: 9.7208\n",
            "Epoch [170/200], Loss: 18.0437\n",
            "Epoch [180/200], Loss: 13.0445\n",
            "Epoch [190/200], Loss: 7.4452\n",
            "Epoch [200/200], Loss: 11.1073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAyCq48TMlWJ"
      },
      "source": [
        "#Exercise 1:\n",
        " Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)\n",
        "#Exercise 2:\n",
        " Try Linear regression on same prediction data using Tensorflow\n",
        "\n",
        " "
      ]
    }
  ]
}