{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-linear-regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "v0BtAX1--7l_"
      },
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "34f006aa7eb4bbc683c39b7059021da900180908",
        "id": "tUurNfvF-7mc"
      },
      "source": [
        "A tensor is a number, vector, matrix or any n-dimensional array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b65b6bb4d15127b1d51f09abf616cfd29fa48b4",
        "id": "DAOgSWEp-7oF"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c1beecda01bc332596edd193cade30006e3f6cbf",
        "id": "-Fi1M6pd-7oJ"
      },
      "source": [
        "We'll create a model that predicts crop yeilds for apples (*target variable*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in different regions. \n",
        "\n",
        "Here's the training data:\n",
        "\n",
        ">Temp | Rain | Humidity | Prediction\n",
        ">--- | --- | --- | ---\n",
        "> 73 | 67 | 43 | 56\n",
        "> 91 | 88 | 64 | 81\n",
        "> 87 | 134 | 58 | 119\n",
        "> 102 | 43 | 37 | 22\n",
        "> 69 | 96 | 70 | 103\n",
        "\n",
        "In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "```\n",
        "\n",
        "It means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n",
        "\n",
        "\n",
        "\n",
        "**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c24b8195c0e9c6e8e13e169d264484f1f9b3b1ae",
        "id": "h0dmV2Fc-7oL"
      },
      "source": [
        "## Training Data\n",
        "The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column for variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dfda99005fc6daf3a49ae1cdd427ccac0aa446b1",
        "id": "MaIf33bV-7oN"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bf56faf74f7e29c9ed7523308718a9ab1acc0667",
        "id": "1tnPriBD-7oa"
      },
      "source": [
        "# Target (apples)\n",
        "targets = np.array([[56], \n",
        "                    [81], \n",
        "                    [119], \n",
        "                    [22], \n",
        "                    [103]], dtype='float32')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "70d48f83ae4fce7aba7dd78fd58dddc77c598bfd",
        "id": "MyJm3YtE-7oo"
      },
      "source": [
        "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "931c1bad8788e607fa100d4338e1b1fe120e2339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZyKnyCc-7oq",
        "outputId": "bc7a08ac-26ce-4ae8-c885-c1bce4b170ea"
      },
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.],\n",
            "        [ 81.],\n",
            "        [119.],\n",
            "        [ 22.],\n",
            "        [103.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "652647cd90bd0784ec4dc53472410f7358ee18c9",
        "id": "y0RLCJnb-7o4"
      },
      "source": [
        "## Linear Regression Model (from scratch)\n",
        "\n",
        "The *weights* and *biases* can also be represented as matrices, initialized with random values. The first row of `w` and the first element of `b` are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6f788ae559355b3f01667be1554a5d2bdcade8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjToROni-7o5",
        "outputId": "f5015652-dd4c-48f9-a3d7-f62f338317f2"
      },
      "source": [
        "# Weights and biases\n",
        "weights = torch.randn(1,3,requires_grad=True)\n",
        "biases = torch.randn(1, requires_grad=True)\n",
        "print(weights)\n",
        "print(biases)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3639, -0.0101,  0.4124]], requires_grad=True)\n",
            "tensor([0.5093], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3579a065997cae41f7f504916b6bc07878ac768c",
        "id": "8qNNejI9-7pH"
      },
      "source": [
        "The *model* is simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b1119f5ae9688a5f31dba438c7f78ca382deb7e3",
        "id": "5G_d0Ka--7pJ"
      },
      "source": [
        "# Define the model\n",
        "def model(x):\n",
        "    return x @ weights.t() + biases\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8e0a4644cb1c4ed68a3bcf67a8a156341ac7c853",
        "id": "nT94e2ZK-7pb"
      },
      "source": [
        "The matrix obtained by passing the input data to the model is a set of predictions for the target variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b042a3cf8f16f4c4380cccbac9d0892719c24190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUpnkKlO-7pd",
        "outputId": "494b8144-1f02-4734-e012-39f29d787d66"
      },
      "source": [
        "# Generate predictions\n",
        "predictions = model(inputs)\n",
        "print(predictions)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -9.0034],\n",
            "        [ -7.1066],\n",
            "        [ -8.5911],\n",
            "        [-21.7887],\n",
            "        [  3.2933]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5551ef933de7902c8b5a38ae3d8e4795cb244f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuIPDbJV-7po",
        "outputId": "ddb06649-85e4-49e9-c5bf-209360797598"
      },
      "source": [
        "# Compare with targets\n",
        "print(targets)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.],\n",
            "        [ 81.],\n",
            "        [119.],\n",
            "        [ 22.],\n",
            "        [103.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2c4a9cf2b3c9152f2f832176bce9a87381e2419c",
        "id": "Q-NuYiwI-7p4"
      },
      "source": [
        "Because we've started with random weights and biases, the model does not perform a good job of predicting the target varaibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "edaae7266f5d47c5e970e1438a812f10d8d35fb4",
        "id": "hiNOZ2g1-7p7"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "We can compare the predictions with the actual targets, using the following method: \n",
        "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
        "* Square all elements of the difference matrix to remove negative values.\n",
        "* Calculate the average of the elements in the resulting matrix.\n",
        "\n",
        "The result is a single number, known as the **mean squared error** (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dbf5bca8cbf2a3831089b454c70469e3748e9682",
        "id": "_wY9fW06-7p9"
      },
      "source": [
        "# MSE loss\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    #.numel method returns the number of elements in a tensor\n",
        "    # torch.sum return all the sum of elements in the tensor \n",
        "    return torch.sum(diff * diff) / diff.numel()\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "90da6779aad81608c40cdca77c3c04b68a815c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V__m5zOU-7qH",
        "outputId": "714af88d-5f50-4c39-91d5-838a68a15962"
      },
      "source": [
        "# Compute loss\n",
        "loss = mse(predictions, targets)\n",
        "print(loss)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8025.3115, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3ab3acadf389f30430b55c26c7979dcffaa974a5",
        "id": "j-TOY_7g-7qS"
      },
      "source": [
        "The resulting number is called the **loss**, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c61acf9c3cff205d769fc52ed3b1b76f5ae66233",
        "id": "kbQQKg0_-7qU"
      },
      "source": [
        "## Compute Gradients\n",
        "\n",
        "With PyTorch, we can automatically compute the gradient or derivative of the `loss` w.r.t. to the weights and biases, because they have `requires_grad` set to `True`.\n",
        "\n",
        "More on autograd:  https://pytorch.org/docs/stable/autograd.html#module-torch.autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ef66710c6ef1944567c4dc033e1ca316f35490ab",
        "id": "jMUIxzeO-7qW"
      },
      "source": [
        "# Compute gradients\n",
        "loss.backward()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6504cddcfb4bfb0817bf03ef460f08f3145a9091",
        "id": "CtacVbsp-7qk"
      },
      "source": [
        "The gradients are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5943d1cef604a178c95f5e8d255519d42d9f9982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWG8jqkG-7qo",
        "outputId": "4d3d5792-8a9f-4992-b875-93263f66d56c"
      },
      "source": [
        "# Gradients for weights\n",
        "print(weights)\n",
        "print(weights.grad)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3639, -0.0101,  0.4124]], requires_grad=True)\n",
            "tensor([[-14083.8320, -16264.2246,  -9773.5586]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "47278e318b156c6a5812e0842dbc4164c8362562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzeDazjr-7qx",
        "outputId": "d751008d-22a0-4dcc-d5d9-d46ccae6d658"
      },
      "source": [
        "# Gradients for bias\n",
        "print(biases)\n",
        "print(biases.grad)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5093], requires_grad=True)\n",
            "tensor([-169.6786])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "466dc3a2cc2d4bd2c10ae4cf59cf4627b5cc9c75",
        "id": "6HohuU-I-7q_"
      },
      "source": [
        "A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases. \n",
        "\n",
        "* If a gradient element is **postive**, \n",
        "    * **increasing** the element's value slightly will **increase** the loss.\n",
        "    * **decreasing** the element's value slightly will **decrease** the loss.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* If a gradient element is **negative**,\n",
        "    * **increasing** the element's value slightly will **decrease** the loss.\n",
        "    * **decreasing** the element's value slightly will **increase** the loss.\n",
        "    \n",
        "\n",
        "\n",
        "The increase or decrease is proportional to the value of the gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "35ed968bfc135bd44eeb100ae401d0628fbc5c63",
        "id": "oRgBMWgV-7rB"
      },
      "source": [
        "Finally, we'll reset the gradients to zero before moving forward, because PyTorch accumulates gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5f02dc376c21857d4e545d98413952c5ac73039b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwkeQev0-7rD",
        "outputId": "04786ae2-a5a9-4e2e-e0b8-1dd2ecae1e97"
      },
      "source": [
        "#Before we proceed, we reset the gradients to zero by calling .zero_() method. \n",
        "#We need to do this, because PyTorch accumulates, gradients i.e. the next time we call .backward on the loss, \n",
        "#the new gradient values will get added to the existing gradient values, which may lead to unexpected results.\n",
        "weights.grad.zero_()\n",
        "biases.grad.zero_()\n",
        "print(weights.grad)\n",
        "print(biases.grad)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.]])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5501c66c9729c4954e9b798a0634a9d84487e639",
        "id": "pjKbQIcT-7rN"
      },
      "source": [
        "## Adjust weights and biases using gradient descent\n",
        "\n",
        "We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n",
        "\n",
        "1. Generate predictions\n",
        "2. Calculate the loss\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "5. Reset the gradients to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ef0d2bd2d9c5acb60992e238439ee00c2223319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbJYF_oB-7rP",
        "outputId": "a9e1ddb5-3640-4aa1-eb9c-409404e981a2"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(predictions)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -9.0034],\n",
            "        [ -7.1066],\n",
            "        [ -8.5911],\n",
            "        [-21.7887],\n",
            "        [  3.2933]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "302ee8226da4ee5d0dad137c638573a79f8abded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt9A0Bzw-7rb",
        "outputId": "4d33fed4-2b99-41b0-96c0-f8f805560350"
      },
      "source": [
        "# Calculate the loss\n",
        "loss = mse(predictions, targets)\n",
        "print(loss)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8025.3115, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "01c596aecf87e4670033ddd4ed36e26b97e2f9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "X3U2apNf-7rp",
        "outputId": "b0dca9ed-8d4c-4680-f32e-7bbbe30197f8"
      },
      "source": [
        "# Compute gradients\n",
        "loss.backward(retain_graph=True)\n",
        "print(weights.grad)\n",
        "print(biases.grad)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-81b2d4d1a4a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWaqAC7XyCCd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKpR8_dvyCHO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ec1e2bdc8f91523e556fad55ee8c01eb5431ae24",
        "id": "Gi8Iw67j-7rz"
      },
      "source": [
        "# Adjust weights & reset gradients\n",
        "#We use torch.no_grad to indicate to PyTorch that we shouldn't track, calculate or modify gradients while updating the weights and biases.\n",
        "#We multiply the gradients with a really small number (10^-5 in this case), to ensure that we don't modify the weights by a really large amount\n",
        "#After we have updated the weights, we reset the gradients back to zero, to avoid affecting any future computations.\n",
        "with torch.no_grad():\n",
        "    weights -= weights.grad * 1e-5\n",
        "    biases -= biases.grad * 1e-5\n",
        "    weights.grad.zero_()\n",
        "    biases.grad.zero_()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1d61b6f61f49b19099d29d1be8ec5ae4967bbd51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB17H1hr-7sD",
        "outputId": "25dbf1b2-90e1-44c7-cdf9-05f9a249f8aa"
      },
      "source": [
        "print(weights)\n",
        "print(biases)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3639, -0.0101,  0.4124]], requires_grad=True)\n",
            "tensor([0.5110], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6af10c29db7cb0d6e869b2c30966a34a48a011e2",
        "id": "YbNSWsxh-7so"
      },
      "source": [
        "With the new weights and biases, the model should have a lower loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c542b5fe75d82454f34cac13cdcff8b48dd1945c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzhhX8xh-7su",
        "outputId": "f3d139d2-9d13-423d-a467-02fd9eafbf62"
      },
      "source": [
        "# Calculate loss\n",
        "prediction = model(inputs)\n",
        "loss = mse(prediction, targets)\n",
        "print(loss)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8025.0244, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5201901695f3ea13d7fdd5d985da7e0761c541d0",
        "id": "JvUhV8nQ-7s9"
      },
      "source": [
        "## Train for multiple epochs\n",
        "\n",
        "To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9f5f0ffeee666b30c5828636359f0be6addbef7c",
        "id": "rX0ZllBO-7tJ"
      },
      "source": [
        "# Train for 100 epochs\n",
        "for i in range(100):\n",
        "    prediction = model(inputs)\n",
        "    loss = mse(prediction, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        weights -= weights.grad * 1e-5\n",
        "        biases -= biases.grad * 1e-5\n",
        "        weights.grad.zero_()\n",
        "        biases.grad.zero_()"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c4820ca48b78f4dc242d80a9ec3ec6aca1aef671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym2eslp8-7ta",
        "outputId": "4e4617a6-705d-41e8-cf3a-f1f184be70ca"
      },
      "source": [
        "# Calculate loss\n",
        "prediction = model(inputs)\n",
        "loss = mse(prediction, targets)\n",
        "print(loss)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19.7027, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bbcd65fa7094cec187565e54c2107e683bea787b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7z9q9g9-7to",
        "outputId": "dff9a6dc-4213-4cc1-b9c4-6d47a5a976c3"
      },
      "source": [
        "# Print predictions\n",
        "prediction"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.5636],\n",
              "        [ 83.4875],\n",
              "        [113.5339],\n",
              "        [ 28.7447],\n",
              "        [ 99.7775]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "addec2c4eca8edfcae5544ea2cc717182c21d90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEjLn-IO-7ty",
        "outputId": "d25d1c3e-08c1-4c83-bd46-7cb8bc210566"
      },
      "source": [
        "# Print targets\n",
        "targets\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.],\n",
              "        [ 81.],\n",
              "        [119.],\n",
              "        [ 22.],\n",
              "        [103.]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f43ASB2tWit"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}